{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ubUJN-0rEHn",
    "outputId": "c24b5e6e-3ced-4242-8acd-0cdc83d2ff7f"
   },
   "outputs": [],
   "source": [
    "#!pip install nltk\n",
    "import json\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "I-2ZygEHrLMT"
   },
   "outputs": [],
   "source": [
    "#1.1\n",
    "# Function to clean and normalize text fields\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', '', text) # Delete no ASCII character\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n",
    "    text = re.sub(r'\\s+', ' ', text) # Replace multiple spaces\n",
    "    tokens = text.split() # Tokenize\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    stemmed = [stemmer.stem(word) for word in tokens] # Apply stemming\n",
    "\n",
    "    return ' '.join(stemmed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xtGxTlHJrM0n"
   },
   "outputs": [],
   "source": [
    "#1.2\n",
    "with open('fashion_products_dataset.json', 'r', encoding='utf-8') as f:\n",
    "    corpus = json.load(f)\n",
    "# Text cleaning to title and description fields\n",
    "for doc in corpus:\n",
    "    doc['title_clean'] = clean_text(doc.get('title', ''))\n",
    "    doc['description_clean'] = clean_text(doc.get('description', ''))\n",
    "\n",
    "REQUIRED_FIELDS = [\n",
    "    'pid', 'title', 'description', 'brand', 'category', 'sub_category',\n",
    "    'product_details', 'seller', 'out_of_stock', 'selling_price',\n",
    "    'discount', 'actual_price', 'average_rating', 'url'\n",
    "]\n",
    "# We ensure all required fields are present in each document\n",
    "def ensure_fields(doc):\n",
    "    for field in REQUIRED_FIELDS:\n",
    "        if field not in doc:\n",
    "            doc[field] = None\n",
    "    return doc\n",
    "\n",
    "# We apply field completion to the entire corpus\n",
    "corpus = [ensure_fields(doc) for doc in corpus]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Creation of a new variable that aggrups multiple features\n",
    "def build_metadata_text(doc):\n",
    "    brand = doc.get('brand', '')\n",
    "    category = doc.get('category', '')\n",
    "    sub_category = doc.get('sub_category', '')\n",
    "    seller = doc.get('seller', '')\n",
    "    product_details = ' '.join(\n",
    "        f\"{k} {v}\" for d in doc.get('product_details', []) for k, v in d.items()\n",
    "    )\n",
    "    return f\"{brand} {category} {sub_category} {product_details} {seller}\".lower()\n",
    "\n",
    "for doc in corpus:\n",
    "    doc['metadata_text'] = build_metadata_text(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "NOAejA9BEb0L"
   },
   "outputs": [],
   "source": [
    "#1.4\n",
    "def normalize_numeric_fields(doc):\n",
    "    # Convert price and rating fields to numeric types\n",
    "    try:\n",
    "        doc['selling_price'] = float(doc['selling_price'].replace(',', ''))\n",
    "    except:\n",
    "        doc['selling_price'] = None\n",
    "    try:\n",
    "        doc['actual_price'] = float(doc['actual_price'].replace(',', ''))\n",
    "    except:\n",
    "        doc['actual_price'] = None\n",
    "    try:\n",
    "        doc['discount'] = int(doc['discount'].replace('% off', '').strip())\n",
    "    except:\n",
    "        doc['discount'] = None\n",
    "    try:\n",
    "        doc['average_rating'] = float(doc['average_rating'])\n",
    "    except:\n",
    "        doc['average_rating'] = None\n",
    "    return doc\n",
    "\n",
    "# We apply normalization to the entire corpus\n",
    "corpus = [normalize_numeric_fields(doc) for doc in corpus]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(corpus)\n",
    "df.info()\n",
    "missing_values_per_column = df.isnull().sum()\n",
    "print(missing_values_per_column)\n",
    "# Drop rows with empty slots for easier analysis\n",
    "df = df.dropna()\n",
    "\n",
    "# Preview of the data\n",
    "df.info()\n",
    "df.head()\n",
    "mean_values = df[['selling_price', 'actual_price', 'discount']].mean()\n",
    "print(mean_values)\n",
    "max_values = df[['selling_price', 'actual_price', 'discount']].max()\n",
    "print(max_values)\n",
    "# Increase overall figure size\n",
    "plt.figure(figsize=(20, 24))  # <- Bigger figure\n",
    "\n",
    "# 1. Actual Price Distribution\n",
    "plt.subplot(3, 2, 1)\n",
    "sns.histplot(df['actual_price'], bins=50, kde=True, color='skyblue')\n",
    "plt.title('Distribution of Actual Price', fontsize=16)\n",
    "plt.xlabel('Actual Price', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "\n",
    "# 2. Distribution of selling_price\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(df['selling_price'], bins=50, kde=True, color='orange')\n",
    "plt.title('Distribution of Selling Price', fontsize=16)\n",
    "plt.xlabel('Selling Price', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 3. Combined distribution of actual_price and selling_price\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(df['actual_price'], bins=50, kde=True, color='skyblue', label='Actual Price', alpha=0.6)\n",
    "sns.histplot(df['selling_price'], bins=50, kde=True, color='orange', label='Selling Price', alpha=0.6)\n",
    "plt.title('Distribution of Actual Price vs Selling Price', fontsize=16)\n",
    "plt.xlabel('Price', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 4. Average Rating Distribution\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(df['average_rating'], bins=10, kde=True, color='lightgreen')\n",
    "plt.title('Distribution of Average Rating', fontsize=16)\n",
    "plt.xlabel('Average Rating', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 5. Count of Different Brands (Top 20)\n",
    "plt.figure(figsize=(12,6))\n",
    "top_brands = df['brand'].value_counts().head(20)\n",
    "sns.barplot(x=top_brands.values, y=top_brands.index, palette='viridis')\n",
    "plt.title('Top 20 Brands by Product Count', fontsize=16)\n",
    "plt.xlabel('Count', fontsize=12)\n",
    "plt.ylabel('Brand', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 6. Count per Category\n",
    "plt.figure(figsize=(12,6))\n",
    "category_counts = df['category'].value_counts()\n",
    "sns.barplot(x=category_counts.values, y=category_counts.index, palette='magma')\n",
    "plt.title('Number of Products per Category', fontsize=16)\n",
    "plt.xlabel('Count', fontsize=12)\n",
    "plt.ylabel('Category', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 7. Discount Distribution\n",
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(df['discount'], bins=30, kde=True, color='salmon')\n",
    "plt.title('Distribution of Discount', fontsize=16)\n",
    "plt.xlabel('Discount (%)', fontsize=12)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.show()\n",
    "\n",
    "# 8. Out of Stock vs In Stock\n",
    "plt.figure(figsize=(12,6))\n",
    "stock_counts = df['out_of_stock'].value_counts()\n",
    "sns.barplot(x=stock_counts.index.map({True: 'Out of Stock', False: 'In Stock'}), y=stock_counts.values, palette='coolwarm')\n",
    "plt.title('Stock Status', fontsize=16)\n",
    "plt.xlabel('Stock Status', fontsize=12)\n",
    "plt.ylabel('Number of Products', fontsize=12)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(corpus)\n",
    "df = df.dropna()  # remove rows with missing values\n",
    "\n",
    "# 2. Word counting and vocabulary \n",
    "all_text = ' '.join(df['description_clean'])\n",
    "words = all_text.split()\n",
    "total_words = len(words)\n",
    "vocab = set(words)\n",
    "vocab_size = len(vocab)\n",
    "word_counts = Counter(words)\n",
    "most_common_words = word_counts.most_common(20)\n",
    "\n",
    "print(\"Total words:\", total_words)\n",
    "print(\"Vocabulary size:\", vocab_size)\n",
    "print(\"Most common words:\", most_common_words)\n",
    " \n",
    "# top 20 most frequent words\n",
    "plt.figure(figsize=(12,6))\n",
    "top_words, top_counts = zip(*most_common_words)\n",
    "sns.barplot(x=list(top_counts), y=list(top_words), palette='viridis')\n",
    "plt.title('Top 20 Most Frequent Words')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Word')\n",
    "plt.show()\n",
    "\n",
    "# 3. Sentence length distribution \n",
    "sentence_lengths = []\n",
    "for desc in df['description']:\n",
    "    for s in sent_tokenize(desc):\n",
    "        sentence_lengths.append(len(word_tokenize(s)))\n",
    "\n",
    "print(\"Average sentence length:\", np.mean(sentence_lengths))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.histplot(sentence_lengths, bins=50, kde=True, color='purple')\n",
    "plt.title('Sentence Length Distribution')\n",
    "plt.xlabel('Words per sentence')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# 4. Rankings \n",
    "print(\"\\n Top 10 products by rating:\")\n",
    "print(df.sort_values(by='average_rating', ascending=False).head(10)[['title','average_rating']])\n",
    "\n",
    "print(\"\\n Top 10 most expensive products:\")\n",
    "print(df.sort_values(by='actual_price', ascending=False).head(10)[['title','actual_price']])\n",
    "\n",
    "print(\"\\n Top 10 products with highest discount:\")\n",
    "print(df.sort_values(by='discount', ascending=False).head(10)[['title','discount']])\n",
    "\n",
    "print(\"\\n Top 10 brands:\")\n",
    "print(df['brand'].value_counts().head(10))\n",
    "\n",
    "print(\"\\nTop 10 sellers:\")\n",
    "print(df['seller'].value_counts().head(10))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

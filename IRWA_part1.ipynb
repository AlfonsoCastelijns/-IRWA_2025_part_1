{"cells":[{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5655,"status":"ok","timestamp":1761208414304,"user":{"displayName":"ENRIC MARTÍNEZ MORELL","userId":"13429171962125163659"},"user_tz":-120},"id":"6ubUJN-0rEHn","outputId":"1a9e639d-a62a-4da0-90ec-919058d4fdb7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.12/dist-packages (1.9.4)\n","Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n","Requirement already satisfied: numpy>=1.6.1 in /usr/local/lib/python3.12/dist-packages (from wordcloud) (2.0.2)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from wordcloud) (11.3.0)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from wordcloud) (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (4.60.1)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (3.2.5)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->wordcloud) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.17.0)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]}],"source":["!pip install nltk wordcloud\n","\n","import json\n","import pandas as pd\n","from collections import Counter\n","import matplotlib.pyplot as plt\n","from wordcloud import WordCloud\n","import nltk\n","from nltk.corpus import stopwords\n","from nltk.stem import PorterStemmer\n","import re\n","\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('english'))\n","stemmer = PorterStemmer()"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1761208414316,"user":{"displayName":"ENRIC MARTÍNEZ MORELL","userId":"13429171962125163659"},"user_tz":-120},"id":"I-2ZygEHrLMT"},"outputs":[],"source":["#1.1\n","# Function to clean and normalize text fields\n","def clean_text(text):\n","    text = text.lower()\n","    text = re.sub(r'[^\\x00-\\x7F]+', '', text) # Delete no ASCII character\n","    text = re.sub(r'[^\\w\\s]', '', text) # Remove punctuation\n","    text = re.sub(r'\\s+', ' ', text) # Replace multiple spaces\n","    tokens = text.split() # Tokenize\n","    tokens = [word for word in tokens if word not in stop_words]\n","    stemmed = [stemmer.stem(word) for word in tokens] # Apply stemming\n","\n","    return ' '.join(stemmed)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":24320,"status":"ok","timestamp":1761208440149,"user":{"displayName":"ENRIC MARTÍNEZ MORELL","userId":"13429171962125163659"},"user_tz":-120},"id":"xtGxTlHJrM0n"},"outputs":[],"source":["#1.2\n","with open('fashion_products_dataset.json', 'r', encoding='utf-8') as f:\n","    corpus = json.load(f)\n","# Text cleaning to title and description fields\n","for doc in corpus:\n","    doc['title_clean'] = clean_text(doc.get('title', ''))\n","    doc['description_clean'] = clean_text(doc.get('description', ''))\n","\n","REQUIRED_FIELDS = [\n","    'pid', 'title', 'description', 'brand', 'category', 'sub_category',\n","    'product_details', 'seller', 'out_of_stock', 'selling_price',\n","    'discount', 'actual_price', 'average_rating', 'url'\n","]\n","# We ensure all required fields are present in each document\n","def ensure_fields(doc):\n","    for field in REQUIRED_FIELDS:\n","        if field not in doc:\n","            doc[field] = None\n","    return doc\n","\n","# Apply field completion to the entire corpus\n","corpus = [ensure_fields(doc) for doc in corpus]\n","\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"NOAejA9BEb0L","executionInfo":{"status":"ok","timestamp":1761208447548,"user_tz":-120,"elapsed":48,"user":{"displayName":"ENRIC MARTÍNEZ MORELL","userId":"13429171962125163659"}}},"outputs":[],"source":["#1.3\n","def normalize_numeric_fields(doc):\n","    # Convert price and rating fields to numeric types\n","    try:\n","        doc['selling_price'] = float(doc['selling_price'].replace(',', '.'))\n","    except:\n","        doc['selling_price'] = None\n","    try:\n","        doc['actual_price'] = float(doc['actual_price'].replace(',', '.'))\n","    except:\n","        doc['actual_price'] = None\n","    try:\n","        doc['discount'] = int(doc['discount'].replace('% off', '').strip())\n","    except:\n","        doc['discount'] = None\n","    try:\n","        doc['average_rating'] = float(doc['average_rating'])\n","    except:\n","        doc['average_rating'] = None\n","    '''\n","    # Ensure out_of_stock is boolean\n","    if isinstance(doc.get('out_of_stock'), str):\n","        doc['out_of_stock'] = doc['out_of_stock'].lower() == 'true'\n","    elif not isinstance(doc.get('out_of_stock'), bool):\n","        doc['out_of_stock'] = None\n","    '''\n","    return doc\n","\n","# Apply normalization to the entire corpus\n","corpus = [normalize_numeric_fields(doc) for doc in corpus]\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}